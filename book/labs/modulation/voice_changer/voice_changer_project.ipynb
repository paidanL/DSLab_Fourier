{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f20b54f3-78db-4242-942e-bd1694b54b32",
   "metadata": {},
   "source": [
    "# Week 8: Build a Voice Changer/Voice Shield\n",
    "\n",
    "<font size=\"6\"> Laboratory 7 </font> <br>\n",
    "<font size=\"3\"> Last updated March 3, 2023 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdb2e48-59be-4d32-8324-49daad3652e9",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange;\"> 00. Content </span>\n",
    "\n",
    "### Mathematics \n",
    "- N/A\n",
    "    \n",
    "### Programming Skills \n",
    "- flow structures (`try`/`finally`, `for`/`else`)\n",
    "- Timing conflicts\n",
    "- Buffers\n",
    "    \n",
    "### Embedded Systems \n",
    "- N/A\n",
    "\n",
    "## <span style=\"color:orange;\"> 0. Required Hardware </span>\n",
    "- Headphones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c6cb81-725b-49e5-8c66-c2f614301457",
   "metadata": {},
   "source": [
    "<h3 style=\"background-color:lightblue\"> Write your name and email below: </h3>\n",
    "\n",
    "**Name:** me \n",
    "\n",
    "**Email:** me @purdue.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f68d33a-a196-420b-885c-31b7a374b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f839845-f55a-433f-aa44-ae17a9cb447d",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange;\"> 1. Intro </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac971b00-162d-4b85-aede-d1c1c1f4b966",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange;\"> 1. Introduction </span>\n",
    "\n",
    "In a previous lab, we learned about modulating signals and in later one, we learned how to capture and manipulate audio using python. That served as a good primer on how to manipulate audio in Python.  We now combine the ideas from the earlier laboratories to create a real-time voice changer. If the time taken for processing data is more than a few milliseconds, we will be forced to either skip sections of audio or have a substantial lag between input and output. In this lab, we will explore ways to minimize latency in producing the modulated output inorder to process the audio in realtime. But before that let us look into audio recordng and playback with Python.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfb928e-1dd4-41a5-8119-a749ae643e4c",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange;\"> 2. Audio Recorder </span>\n",
    "We will be using PyAudio for making our voice changer\n",
    "To explore more in detail about PyAudio and its features, you could refer the [API docementation for PyAudio](https://people.csail.mit.edu/hubert/pyaudio/docs/).\n",
    "\n",
    "For Recording Audio with Python, we have to do the following:\n",
    "1. Open a data stream to get audio data frame from microphone\n",
    "2. Iterate over the stream and append each frame to a list of frames.\n",
    "3. Stop and close the data stream.\n",
    "4. Save the data frames as a .wave file.\n",
    "5. Close and terminate the audio stream.\n",
    "\n",
    "[Voice_recorder.py](https://github.com/TheDataScienceLabs/DSLab_Fourier/blob/main/book/labs/modulation/tremolo_beats/voice_recorder.py) is implemented following the above pseudo code. It records 5s of mono channel audio and saves it as 'my_recording.wav'.\n",
    "\n",
    "\n",
    "Let us go through the code in voice_recorder.py.\n",
    "```\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format = FORMAT,\n",
    "                channels = CHANNELS,\n",
    "                rate = RATE,\n",
    "                input = True,\n",
    "                frames_per_buffer = chunk)\n",
    "```\n",
    "\n",
    "Here we are initializing an Audio stream. Since we enabled input as True, python will recognize this stream as an input audio stream.\n",
    "\n",
    "```\n",
    "for i in range(0, RATE//chunk * RECORD_SECONDS):\n",
    "\n",
    "    frame = stream.read(chunk, exception_on_overflow = False)\n",
    "    frames.append(frame)\n",
    "\n",
    "```\n",
    "\n",
    "This is the part where we read 'chunk' sized samples from the input audio stream.\n",
    "These samples are then appended to a list. The list of samples can be saved as a wav file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51fea49-2eb6-4f3b-86e8-50c88914b7bf",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Exercise 1</span>\n",
    "\n",
    "What role does ```exception_on_overflow = False``` do in ```frame = stream.read(chunk, exception_on_overflow = False)``` on [voice_recorder.py](https://github.com/TheDataScienceLabs/DSLab_Fourier/blob/main/book/labs/modulation/tremolo_beats/voice_recorder.py)? Run the code after setting ```exception_on_overflow = True``` and report your observations. What does the result indicate ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e0436e-f035-48dd-8929-cfaca4a6507b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ddddcab-5c4a-41ee-9755-c059e92e64f2",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange;\"> 2. Audio Player </span>\n",
    "\n",
    "The idea behind the implementation of an audio player is similar but opposite to that of an audio recorder.\n",
    "Since we have the audio file saved in some format, a naive approach would be to load the audio as a single numpy array and play it using Audio() function.\n",
    "\n",
    "But this approach is not an optimal solution when dealing with huge files.\n",
    "\n",
    "So a good approach will be to read smaller chunks at a time from the audio file, so that we do not exhaust our total system memory.\n",
    "\n",
    "The Pseudo code for the audio recording using python and PyAudio is as follows:\n",
    "\n",
    "1. Initialize and open an output audio stream.\n",
    "2. Iterate and read frames of data from the audio file.\n",
    "3. Write the data frames to the output stream.\n",
    "4. Close and terminate the audio stream.\n",
    "\n",
    "[Audio_player.py](https://github.com/TheDataScienceLabs/DSLab_Fourier/blob/main/book/labs/modulation/voice_changer/audio_player.py) is implemented following the above pseudo code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58257b6c-3195-4ef4-82d2-987c35b05f43",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Exercise 2</span>\n",
    "\n",
    "Record a 10s audio clip using [voice_recorder.py](https://github.com/TheDataScienceLabs/DSLab_Fourier/blob/main/book/labs/modulation/tremolo_beats/voice_recorder.py) and then play the 10s audio using [audio_player.py](https://github.com/TheDataScienceLabs/DSLab_Fourier/blob/main/book/labs/modulation/voice_changer/audio_player.py). Report your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebae697d-6777-45de-bb91-dea25cfc6c71",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange;\"> 3. Megaphone - a Pythonic Approach </span>\n",
    "\n",
    "A megaphone is a portable, cone-shaped device used to amplify a person's voice. It is a simple device to amplify input sounds in realtime. In this exercise we will be using python to implememt a Megahorn in realtime.\n",
    "\n",
    "To implement such a device, we follow these steps:\n",
    "1. Initialize and open an input and output stream.\n",
    "2. Read frames from the input stream.\n",
    "3. Write the frames from the input stream to the output stream.\n",
    "4. Close and terminate the data streams.\n",
    "\n",
    "[Megaphone.py](https://github.com/TheDataScienceLabs/DSLab_Fourier/blob/main/book/labs/modulation/voice_changer/megaphone.py) is implemented following the steps above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e888d79-d880-4c0e-a636-2825c289621e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3f3731e-43d2-4433-8878-6a7708292e9e",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Exercise 3</span>\n",
    "\n",
    "Run [Megaphone.py](https://github.com/TheDataScienceLabs/DSLab_Fourier/blob/main/book/labs/modulation/voice_changer/megaphone.py) and report your observations. How well does this program perform when you are not using headphones? Report your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e954e042-a357-465c-9159-2e5d0233a564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75b1c772-5d89-4095-8ed6-33061b2943d5",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange;\"> 4. Voice Changer </span>\n",
    "\n",
    "Voice changers are one of those gadgets that you might have seen in spy movies or as a part of Halloween costumes. \n",
    "\n",
    "When you speak, your throat produces a vibration which travels as a wave. Essentially,\n",
    "your voice is a sound wave. A voice changer, changes the shape of this sound wave by altering it. This can be done in multiple ways.\n",
    "\n",
    "One of the ways to implement a voice changer is to find out the frequency components of your voice and replace those frequency components with another frequency. However this is computationally expensive and will require specialized hardware to run the operation in realtime.\n",
    "\n",
    "A simple way to do this is to multiply the received audio signal with a wave of known frequency. This will shift the frequency components of the signal altering your voice. [\n",
    "\n",
    "To implement such a device, we will do the following:\n",
    "1. Initialize and open an input and output stream.\n",
    "2. Read frames from the input stream.\n",
    "3. Multiply each such audio frames with a wave of known frequency.\n",
    "4. Write these modified audio frames to the output stream.\n",
    "5. Close and terminate the data streams.\n",
    "\n",
    "[Real_time_voice_changer.py](https://github.com/TheDataScienceLabs/DSLab_Fourier/blob/main/book/labs/modulation/voice_changer/real_time_voice_changer.py) is implemented using this approach.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74efef22-c577-4672-bb06-986007e1e42e",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Exercise 4</span>\n",
    "\n",
    "Run [Real_time_voice_changer.py](https://github.com/TheDataScienceLabs/DSLab_Fourier/blob/main/book/labs/modulation/voice_changer/real_time_voice_changer.py) and report your observations.\n",
    "Identify the frequency of the wave used in altering the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac4249a-2c0c-4240-8500-99d8ca057117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0695ff27-4c68-434a-8ff7-29b58db2afaf",
   "metadata": {},
   "source": [
    "## <span style=\"color:green;\"> Reflection </span>\n",
    "\n",
    "Do not skip this section! Lab will be graded only on completion of this section.\n",
    "\n",
    "__1. What parts of the lab, if any, do you feel you did well? <br>\n",
    "2. What are some things you learned today? <br>\n",
    "3. Are there any topics that could use more clarification? <br>\n",
    "4. Do you have any suggestions on parts of the lab to improve?__\n",
    "\n",
    "<h3 style=\"background-color:lightblue\"> Write Answers for the Reflection Below </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2770226-0bfd-49e8-8c1c-02507639179e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
